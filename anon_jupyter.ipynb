{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae552ad1",
   "metadata": {},
   "source": [
    "## Anonmymizing the customer_information.csv and calculating the k-anonymity of the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545484e4",
   "metadata": {},
   "source": [
    "Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f8e90ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "import country_converter as coco\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3071a7",
   "metadata": {},
   "source": [
    "Loading the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b5970dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data to be anonymised\n",
    "data = pd.read_csv(\"Data/customer_information.csv\")\n",
    "\n",
    "# Declaring variables\n",
    "postcode_dictionary = pd.read_csv('Data/postcode_region.csv')\n",
    "northern_countries = [\"Svalbard & Jan Mayen Islands\"]\n",
    "southern_countries = [\"Micronesia\"]\n",
    "\n",
    "# Create anon_data variable as initial data with unneeded direct identifiers dropped\n",
    "#anon_data = data.drop(['given_name', 'surname', 'phone_number', 'national_insurance_number', 'bank_account_number'], axis=1)\n",
    "anon_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8ae51be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NIN formatting and assign Sample ID as a hashed form of the NIN\n",
    "key = os.urandom(16)\n",
    "data[\"national_insurance_number\"], anon_data['Sample.ID'], salts = zip(*data[\"national_insurance_number\"].apply(\n",
    "    lambda x: hash(key, re.sub(r'(.{2})(?!$)','\\\\1 ', x.replace(' ', '') ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "da04a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference table between NIN and respective hashed NIN\n",
    "reference_table = pd.DataFrame()\n",
    "reference_table['Hashed.NIN'] = anon_data['Sample.ID']\n",
    "reference_table['Salt'] = salts\n",
    "reference_table['Key'] = key.hex()\n",
    "reference_table['NIN'] = data['national_insurance_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "06a31d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign gender\n",
    "anon_data['Gender'] = data['gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "32d0a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding birth date\n",
    "birthyears = pd.DatetimeIndex(data['birthdate']).year\n",
    "# Band the birth years into 5-year intervals\n",
    "anon_data['Birthyear'] = pd.cut(birthyears, np.arange(birthyears.min(), birthyears.max()+20, 20), right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "82f9f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping education level, postcode, and country of birth\n",
    "\n",
    "# Assign education level as banded education level\n",
    "#from tkinter import E\n",
    "anon_data['Education.Level'] = data['education_level'].map(lambda x: \"Higher\" if x in [\"bachelor\", \"masters\", \"phD\"] else \"BasicOther\")\n",
    "\n",
    "# Assign UK country derived from postcode\n",
    "anon_data['Postcode'] = data['postcode'].apply(lambda x: re.search('[a-zA-Z]*', x).group(0))\n",
    "anon_data = pd.merge(anon_data, postcode_dictionary, on='Postcode', how='left')\n",
    "anon_data = anon_data.rename(columns={'Region': 'UK.Region'})\n",
    "\n",
    "# Assign hemisphere of birth depending on country of birth\n",
    "\n",
    "def parse_country(country_name):\n",
    "    country = coco.convert(country_name, to='name_short', include_obsolete=True)\n",
    "    return country\n",
    "\n",
    "def country_to_hemisphere2(country_name):\n",
    "    try:  \n",
    "        if country_name in southern_countries: # Hard-coded fix for unmatched territories\n",
    "            return \"Southern Hemisphere\" \n",
    "        elif country_name in northern_countries:\n",
    "            return \"Northern Hemisphere\"\n",
    "        else:\n",
    "            return (\"Southern\" if Nominatim(user_agent=\"CDM\").geocode(parse_country(country_name)).latitude < 0 else \"Northern\") + \" Hemisphere\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"Error\"\n",
    "\n",
    "anon_data['Location.of.Birth'] = data['country_of_birth'].apply(lambda x: country_to_hemisphere2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "144a2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gaussian noise to weight/height, countries visited, and alcohol/smoking history\n",
    "weight_noise = np.random.normal(0,1,1000)*5\n",
    "anon_data['Weight'] = round(data['weight']+weight_noise, 1)\n",
    "\n",
    "height_noise = np.random.normal(0,1,1000)/5\n",
    "anon_data['Height'] = round(data['height']+height_noise, 2)\n",
    "bmi = data['weight'] / data['height']**2\n",
    "\n",
    "countries_noise = np.random.normal(0,1,1000)*5\n",
    "anon_data['Countries.Visited'] = round(data['n_countries_visited']+countries_noise)\n",
    "\n",
    "alcohol_noise = np.random.normal(0,1,1000)\n",
    "anon_data['Avg.Alcohol'] = round(data['avg_n_drinks_per_week']+alcohol_noise, 1)\n",
    "\n",
    "smoking_noise = np.random.normal(0,1,1000)*20\n",
    "anon_data['Avg.Cigarettes'] = round(data['avg_n_cigret_per_week']+smoking_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e2aa7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach case-control status\n",
    "anon_data['CC.Status'] = data['cc_status']\n",
    "\n",
    "# Re-order columns\n",
    "anon_data = anon_data[['Sample.ID', 'Gender', 'Birthyear', 'Location.of.Birth', 'UK.Region', 'Weight', 'Height', 'Education.Level', 'Avg.Alcohol', 'Avg.Cigarettes', 'CC.Status']]\n",
    "\n",
    "# View the anonymised dataset\n",
    "anon_data\n",
    "\n",
    "# Output the files\n",
    "anon_data.to_csv(\"output.csv\", sep=\",\", index=None)\n",
    "reference_table.to_csv(\"reference_table.csv\", sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f3a90bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Gender, Birthyear, Location.of.Birth, UK.Region, Education.Level, Count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calculating K-anonymity\n",
    "\n",
    "# Checking k-anonymity for quasi-identifiers\n",
    "df_count = anon_data.groupby(['Gender', 'Birthyear', 'Location.of.Birth', 'UK.Region', 'Education.Level']).size().reset_index(name = 'Count') \n",
    "\n",
    "# Print those not meeting our specified k-anonymity level\n",
    "print(df_count[df_count['Count']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "46bed23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZZ 19 48 92 T\n",
      "c39422b6c493d5aeb0506a69396b34a415dcbb1b28a27661723a985f6936a25c\n",
      "f4307052ba3ac64c31769876849d6330\n",
      "b'\\xc88\\xb6\\n\\xff\\xaf\\xba\\xc6\\x9e\\xe9\\x92\\x1e\\xd6{\\x95\\xdb'\n",
      "c838b60affafbac69ee9921ed67b95db\n",
      "b'\\xc88\\xb6\\n\\xff\\xaf\\xba\\xc6\\x9e\\xe9\\x92\\x1e\\xd6{\\x95\\xdb'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"bytes\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39581/783236820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msalt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b5bf8c87675fd09d3d618b246e0410cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mhashed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ZZ 19 48 92 T\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# Should make d5bb9cd05c73ea8aae516a477037e712137566538b13ebb1e9dae2364c02ecb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"bytes\") to str"
     ]
    }
   ],
   "source": [
    "key = os.urandom(16)\n",
    "cnin, hnin, salts = hash(key, re.sub(r'(.{2})(?!$)','\\\\1 ', \"ZZ 19 48 92 T\".replace(' ', '') ))\n",
    "\n",
    "print(cnin)\n",
    "print(hnin) #hashed val\n",
    "print(salts) #salt\n",
    "print(key)\n",
    "print(key.hex()) #key\n",
    "print(bytes.fromhex(key.hex()))\n",
    "\n",
    "\n",
    "#reference_table.to_csv(\"reference_table.csv\", sep=\",\", index=None)\n",
    "key = bytes.fromhex('621253bce31095abc85566ad4c5e9f75')\n",
    "salt = bytes.fromhex('b5bf8c87675fd09d3d618b246e0410cf')\n",
    "\n",
    "hashed = hashlib.sha256(key + salt + \"ZZ 19 48 92 T\".encode()).hexdigest()\n",
    "# Should make d5bb9cd05c73ea8aae516a477037e712137566538b13ebb1e9dae2364c02ecb1\n",
    "\n",
    "hashed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb258010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('hda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "caa27b422802b4fe8c2ce0d4ce59ab3cbffba11e0630735fb9c7a91a54a91b7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
